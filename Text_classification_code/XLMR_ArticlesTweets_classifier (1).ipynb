{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLMR-Articles+Tweets-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9ca6244893e4cbe91853496ad08f1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_922d035525bd4adc80018d454024572e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eff4c239a8064db288bad592489d5964",
              "IPY_MODEL_ec2fe1ced04a4943b245e5c2ef2aaa3a"
            ]
          }
        },
        "922d035525bd4adc80018d454024572e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eff4c239a8064db288bad592489d5964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfd2fb6a837748a990cb802fc9cfa5e2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77113ee1d86242b797d22ad189d4269e"
          }
        },
        "ec2fe1ced04a4943b245e5c2ef2aaa3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b2b5062bfdd42b28a28a63c9e55d5ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [00:04&lt;00:00, 1.08MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6633d15966a4aaca3180702112d516f"
          }
        },
        "cfd2fb6a837748a990cb802fc9cfa5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77113ee1d86242b797d22ad189d4269e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b2b5062bfdd42b28a28a63c9e55d5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6633d15966a4aaca3180702112d516f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13847a29b48d46b98258c21cd36f978f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_265f7ad895c14c4ba4c1fde62f88fad6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4c6a0894a704cc981b3837bfa477320",
              "IPY_MODEL_930e6541026944639ca65e772b5d7e49"
            ]
          }
        },
        "265f7ad895c14c4ba4c1fde62f88fad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4c6a0894a704cc981b3837bfa477320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e8d44ab74114b9bbb29ebf053e3fcdb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b3e8ae16773437188b54a78b778b94f"
          }
        },
        "930e6541026944639ca65e772b5d7e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9eead7f3d1fd49858989c1b54483361b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:34&lt;00:00, 14.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5643b7a7e3ff4aebb0940f9c2d8bfd8e"
          }
        },
        "6e8d44ab74114b9bbb29ebf053e3fcdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b3e8ae16773437188b54a78b778b94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9eead7f3d1fd49858989c1b54483361b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5643b7a7e3ff4aebb0940f9c2d8bfd8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cfd3c81a8564523882abb1ef8e10ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_88f90d64735d47f19084c4cbe5bacb06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b19b9d38d5dd4b8b8506c239be282b72",
              "IPY_MODEL_a25b4924f82d470a99db9dce54cfecb4"
            ]
          }
        },
        "88f90d64735d47f19084c4cbe5bacb06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b19b9d38d5dd4b8b8506c239be282b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_508d81e0effc4d6890f5357e3bd1b254",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13908ddf7b584f0392298da22aee9f68"
          }
        },
        "a25b4924f82d470a99db9dce54cfecb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5eb9450267cc4c6a8ddc06acbd7c7fb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.12G/1.12G [00:27&lt;00:00, 41.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f8badd9e01e4ded9bac62841fa67c54"
          }
        },
        "508d81e0effc4d6890f5357e3bd1b254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13908ddf7b584f0392298da22aee9f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5eb9450267cc4c6a8ddc06acbd7c7fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f8badd9e01e4ded9bac62841fa67c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ojSZ5hvYnvV"
      },
      "source": [
        "# Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlW7YHjGz0o5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1337)\n",
        "from keras import Sequential\n",
        "from keras.utils import Sequence\n",
        "from keras.layers import LSTM, Dense, Masking\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JEJQ70-Ze4X"
      },
      "source": [
        "# Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VfMm_0KtzaY",
        "outputId": "df8eecca-6213-4c51-b4b5-b149f839d923"
      },
      "source": [
        "gpu_info = !nvidia-smi\r\n",
        "gpu_info = '\\n'.join(gpu_info)\r\n",
        "if gpu_info.find('failed') >= 0:\r\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\r\n",
        "  print('and then re-execute this cell.')\r\n",
        "else:\r\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar 15 14:56:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l_bndzvuNBi",
        "outputId": "fc841f7b-de8f-4bf9-a159-85c7f7ad6a94"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBfJmzLmuNJs",
        "outputId": "0a8f9866-69d6-4441-abc4-662c29321dae"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install spacy \r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 26.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 34.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=a9fc9ce79c74e698dab2582826382107f3e0fb0849ece79a3539f4ea441b1b86\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-5psNtwuSbH"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import fnmatch\r\n",
        "import os\r\n",
        "import random\r\n",
        "import re\r\n",
        "import threading\r\n",
        "import librosa,librosa.display\r\n",
        "import tensorflow as tf\r\n",
        "from six.moves import xrange\r\n",
        "import time\r\n",
        "import json\r\n",
        "import torch as t\r\n",
        "import tqdm\r\n",
        "import soundfile\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torch.utils.data import Dataset,DataLoader\r\n",
        "from torch.utils.data.distributed import DistributedSampler\r\n",
        "from time import sleep\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import math\r\n",
        "import pickle\r\n",
        "import functools\r\n",
        "import sentencepiece"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J880Mj8Ouj86"
      },
      "source": [
        "work_dir = '/content/drive/My Drive/Inter-IIT/'\r\n",
        "article_path = '/content/drive/My Drive/Inter-IIT/Development Data/dev_data_article.xlsx'\r\n",
        "#tweet_path = '/content/drive/My Drive/Inter-IIT/Development Data/dev_data_tweet.xlsx'\r\n",
        "tweet_path = '/content/drive/My Drive/Inter-IIT/Development Data/q1.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEzsPnd2u6fM"
      },
      "source": [
        "train_raw = pd.DataFrame(pd.read_excel(article_path)) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "iEsuq86FulXK",
        "outputId": "1638589a-2bb2-4cac-c994-a05d59b806f6"
      },
      "source": [
        "#train_raw = pd.read_csv(article_path)\r\n",
        "train_raw.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>article_0001</td>\n",
              "      <td>Digitisation is one of the key buzzwords in th...</td>\n",
              "      <td>Pakistan’s digital landscape post-Covid</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>article_0002</td>\n",
              "      <td>Increase in tolerance limit up to 120 per cent...</td>\n",
              "      <td>Affordable housing gets shot in the arm</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>article_0003</td>\n",
              "      <td>Home &gt; News &gt; World Sports News\\n\\nJonas Lossl...</td>\n",
              "      <td>Jonas Lossl leaves Everton to rejoin first clu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>article_0004</td>\n",
              "      <td>Source: Agfax.com\\n\\nBy Keith Brown, DTN Contr...</td>\n",
              "      <td>DTN Cotton Closing: Cotton Higher on Commoditi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>article_0005</td>\n",
              "      <td>United Nations, Feb 4: The Serum Institute of ...</td>\n",
              "      <td>Serum Institute of India, UNICEF enter into lo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Text_ID  ... Mobile_Tech_Flag\n",
              "0  article_0001  ...                0\n",
              "1  article_0002  ...                0\n",
              "2  article_0003  ...                0\n",
              "3  article_0004  ...                0\n",
              "4  article_0005  ...                0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-wUOQPSvFnU"
      },
      "source": [
        "train_raw = train_raw[['Text','Mobile_Tech_Flag']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "EqqkYAQHvmvt",
        "outputId": "eb52069b-b00e-40cf-969a-4bede2bbc667"
      },
      "source": [
        "#train_raw = pd.read_csv(article_path)\r\n",
        "train_raw.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Digitisation is one of the key buzzwords in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Increase in tolerance limit up to 120 per cent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Home &gt; News &gt; World Sports News\\n\\nJonas Lossl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Source: Agfax.com\\n\\nBy Keith Brown, DTN Contr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>United Nations, Feb 4: The Serum Institute of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Mobile_Tech_Flag\n",
              "0  Digitisation is one of the key buzzwords in th...                 0\n",
              "1  Increase in tolerance limit up to 120 per cent...                 0\n",
              "2  Home > News > World Sports News\\n\\nJonas Lossl...                 0\n",
              "3  Source: Agfax.com\\n\\nBy Keith Brown, DTN Contr...                 0\n",
              "4  United Nations, Feb 4: The Serum Institute of ...                 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6kyJH661det",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41924e6e-9a22-423e-c8cf-d53551fa73c8"
      },
      "source": [
        "train_raw.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUYuv-yoGnun"
      },
      "source": [
        "## Concatenating tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LKXxDr0Gqfx"
      },
      "source": [
        "df_tweet = pd.read_csv(tweet_path)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mcAIVocGqWR"
      },
      "source": [
        "df_tweet = df_tweet.drop(['Tweet_ID'],axis = 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KIWLGyrG4Dt",
        "outputId": "1f44f5f3-2887-4d45-e7f7-46ff857438dd"
      },
      "source": [
        "df_tweet['Mobile_Tech_Tag'].value_counts()             #Counting the labels "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3000\n",
              "1    1000\n",
              "Name: Mobile_Tech_Tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "AD1VXNmMHcCG",
        "outputId": "28cf47c3-cc69-4aa6-e6c0-a02dd62ecb40"
      },
      "source": [
        "df_tweet.rename(columns={'Tweet':'Text','Mobile_Tech_Tag': 'Mobile_Tech_Flag'})"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>You'll 💜 my #PitchWars book if you like: 🦋 hat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@SkySportsNews: 🚨 Breaking: #WBA have reached ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@stealyoman_cuso: really says a lot about soci...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@PGtzsche1: HPV vaccines increased serious ner...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ramaphosa says if you are positive you must se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>@ZeeNews: चीनी मोबाइल कंपनी रियलमी ने अपना Rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>@ZeeNews: चीनी मोबाइल कंपनी रियलमी ने अपना Rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>चीनी मोबाइल कंपनी रियलमी ने अपना Realme V15 5G...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>@AnjaliSingh_IN: Aapne phone hi galat choose K...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>@ManojSaru: पर bhaib5g इंडिया में कब आयेगा। ; ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Mobile_Tech_Flag\n",
              "0     You'll 💜 my #PitchWars book if you like: 🦋 hat...                 0\n",
              "1     @SkySportsNews: 🚨 Breaking: #WBA have reached ...                 0\n",
              "2     @stealyoman_cuso: really says a lot about soci...                 0\n",
              "3     @PGtzsche1: HPV vaccines increased serious ner...                 0\n",
              "4     Ramaphosa says if you are positive you must se...                 0\n",
              "...                                                 ...               ...\n",
              "3995  @ZeeNews: चीनी मोबाइल कंपनी रियलमी ने अपना Rea...                 1\n",
              "3996  @ZeeNews: चीनी मोबाइल कंपनी रियलमी ने अपना Rea...                 1\n",
              "3997  चीनी मोबाइल कंपनी रियलमी ने अपना Realme V15 5G...                 1\n",
              "3998  @AnjaliSingh_IN: Aapne phone hi galat choose K...                 1\n",
              "3999  @ManojSaru: पर bhaib5g इंडिया में कब आयेगा। ; ...                 1\n",
              "\n",
              "[4000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "sJJrQWtfGnSb",
        "outputId": "a5bc5087-ba1d-4042-ae4d-d2092200c6fa"
      },
      "source": [
        "pd.concat([train_raw,df_tweet.rename(columns={'Tweet':'Text','Mobile_Tech_Tag': 'Mobile_Tech_Flag'})], ignore_index=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Digitisation is one of the key buzzwords in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Increase in tolerance limit up to 120 per cent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Home &gt; News &gt; World Sports News\\n\\nJonas Lossl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Source: Agfax.com\\n\\nBy Keith Brown, DTN Contr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>United Nations, Feb 4: The Serum Institute of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>@ZeeNews: चीनी मोबाइल कंपनी रियलमी ने अपना Rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>@ZeeNews: चीनी मोबाइल कंपनी रियलमी ने अपना Rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>चीनी मोबाइल कंपनी रियलमी ने अपना Realme V15 5G...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>@AnjaliSingh_IN: Aapne phone hi galat choose K...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>@ManojSaru: पर bhaib5g इंडिया में कब आयेगा। ; ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Mobile_Tech_Flag\n",
              "0     Digitisation is one of the key buzzwords in th...                 0\n",
              "1     Increase in tolerance limit up to 120 per cent...                 0\n",
              "2     Home > News > World Sports News\\n\\nJonas Lossl...                 0\n",
              "3     Source: Agfax.com\\n\\nBy Keith Brown, DTN Contr...                 0\n",
              "4     United Nations, Feb 4: The Serum Institute of ...                 0\n",
              "...                                                 ...               ...\n",
              "7995  @ZeeNews: चीनी मोबाइल कंपनी रियलमी ने अपना Rea...                 1\n",
              "7996  @ZeeNews: चीनी मोबाइल कंपनी रियलमी ने अपना Rea...                 1\n",
              "7997  चीनी मोबाइल कंपनी रियलमी ने अपना Realme V15 5G...                 1\n",
              "7998  @AnjaliSingh_IN: Aapne phone hi galat choose K...                 1\n",
              "7999  @ManojSaru: पर bhaib5g इंडिया में कब आयेगा। ; ...                 1\n",
              "\n",
              "[8000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4atnTmcKGnbK"
      },
      "source": [
        "train_raw = pd.concat([train_raw,df_tweet.rename(columns={'Tweet':'Text','Mobile_Tech_Tag': 'Mobile_Tech_Flag'})], ignore_index=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hr1v_VoZqws"
      },
      "source": [
        "# Preprocessing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbxSBv8m6XaR"
      },
      "source": [
        "Select non null:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmb8-t51zx0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644128c0-cb15-4170-d7c8-7c7e56ee0683"
      },
      "source": [
        "train_raw = train_raw[train_raw.Text.notnull()]\n",
        "train_raw.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAMdnQBv1qlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d55b89bd-de5b-4ed5-8a2a-7b2ad9d676f3"
      },
      "source": [
        "train_raw.Text.apply(lambda x: len(x.split())).plot(kind='hist')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc25572110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGyH4kwB0TH6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "bd4fb3d6-84a1-4949-a3df-65c0635c9186"
      },
      "source": [
        "train_raw['len_txt'] =train_raw.Text.apply(lambda x: len(x.split()))\n",
        "train_raw.describe()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8000.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.246750</td>\n",
              "      <td>299.901500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.431147</td>\n",
              "      <td>529.864237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>62.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>400.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>6489.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Mobile_Tech_Flag      len_txt\n",
              "count       8000.000000  8000.000000\n",
              "mean           0.246750   299.901500\n",
              "std            0.431147   529.864237\n",
              "min            0.000000     3.000000\n",
              "25%            0.000000    34.000000\n",
              "50%            0.000000    62.000000\n",
              "75%            0.000000   400.250000\n",
              "max            1.000000  6489.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqFgGC_TkvyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eafd928-d849-4549-c1d5-2ed08c1539bb"
      },
      "source": [
        "train_raw.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jG9xKs1CJnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76133671-db93-4963-c981-47f9536004e1"
      },
      "source": [
        "for l in np.unique(train_raw['Mobile_Tech_Flag']):\n",
        "  print(l)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjTcB2IElYK-"
      },
      "source": [
        "train = train_raw.copy()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KSdpULo4vBM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a99cec0a-6757-41eb-daa1-32b2f78e2b65"
      },
      "source": [
        "train = train.reindex(np.random.permutation(train.index))\n",
        "train.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5901</th>\n",
              "      <td>@Ranjeet16575196 @AmitShah @narendramodi buddy...</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6601</th>\n",
              "      <td>@gauravcsawant: What did India set out to do w...</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7056</th>\n",
              "      <td>@MadhavSheth1: We are the pioneers of 64 MP Sm...</td>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4280</th>\n",
              "      <td>@AnfieldEditon: Liverpool are hesitant to proc...</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2669</th>\n",
              "      <td>CBSE Single Girl Child Scholarship 2020 Applic...</td>\n",
              "      <td>0</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  ...  len_txt\n",
              "5901  @Ranjeet16575196 @AmitShah @narendramodi buddy...  ...       48\n",
              "6601  @gauravcsawant: What did India set out to do w...  ...      105\n",
              "7056  @MadhavSheth1: We are the pioneers of 64 MP Sm...  ...       46\n",
              "4280  @AnfieldEditon: Liverpool are hesitant to proc...  ...       39\n",
              "2669  CBSE Single Girl Child Scholarship 2020 Applic...  ...      313\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJaaGqEC61Tw"
      },
      "source": [
        "Clean the text columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3EJew8g5cUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8d24efe6-2f1e-4c31-8d88-add14379dd89"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(train, test_size=0.2, random_state=35)\n",
        "train.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7854</th>\n",
              "      <td>@YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन ...</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5811</th>\n",
              "      <td>@abccare Aditya Birla company fraud 8400 se ru...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>Oral health and hygiene market in Ireland is c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>768</th>\n",
              "      <td>The World Health Organization has set the reco...</td>\n",
              "      <td>0</td>\n",
              "      <td>713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>709</th>\n",
              "      <td>Bismah Malik By\\n\\nExpress News Service\\n\\nBEN...</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  ...  len_txt\n",
              "7854  @YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन ...  ...       16\n",
              "5811  @abccare Aditya Birla company fraud 8400 se ru...  ...       51\n",
              "1456  Oral health and hygiene market in Ireland is c...  ...     1148\n",
              "768   The World Health Organization has set the reco...  ...      713\n",
              "709   Bismah Malik By\\n\\nExpress News Service\\n\\nBEN...  ...      434\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cr7Ch3_5rnH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "405abd78-2fd0-41a1-a26b-67de4894ff80"
      },
      "source": [
        "train.reset_index(drop=True, inplace=True)\n",
        "train.head(2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन ...</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@abccare Aditya Birla company fraud 8400 se ru...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Mobile_Tech_Flag  len_txt\n",
              "0  @YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन ...                 1       16\n",
              "1  @abccare Aditya Birla company fraud 8400 se ru...                 0       51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-1O5J9G54hV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "37c30035-9642-43f9-a361-2d5200bb0684"
      },
      "source": [
        "val.reset_index(drop=True, inplace=True)\n",
        "val.head(2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>नई दिल्ली। भारतीय रिजर्व बैंक ऑफ इंडिया ने अहम...</td>\n",
              "      <td>0</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ministry of Finance\\n\\nRevised Issuance Calend...</td>\n",
              "      <td>0</td>\n",
              "      <td>587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Mobile_Tech_Flag  len_txt\n",
              "0  नई दिल्ली। भारतीय रिजर्व बैंक ऑफ इंडिया ने अहम...                 0      250\n",
              "1  Ministry of Finance\\n\\nRevised Issuance Calend...                 0      587"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziIsgHqrz0n6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8f7c8b-360d-4452-c9ee-06bd6e794aaf"
      },
      "source": [
        "val.shape, train.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1600, 3), (6400, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YGONt0p60Ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5792d7c1-dc6a-4823-8efd-712493a65b62"
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "print(\"Validation Set Shape :\", val.shape)\n",
        "# print(\"Test Set Shape :\", test.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape : (6400, 3)\n",
            "Validation Set Shape : (1600, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6NYKx4P7N66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba34837-3ce4-48ec-9982-69a37a87b71d"
      },
      "source": [
        "DATA_COLUMN = 'Text'\n",
        "LABEL_COLUMN = 'Mobile_Tech_Flag'\n",
        "# The list containing all the classes (train['SECTION'].unique())\n",
        "label_list = [x for x in np.unique(train.Mobile_Tech_Flag)]\n",
        "label_list"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOSEd24bbiUq"
      },
      "source": [
        "# Splitting the Data into smaller chunks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ausf5AlOkPCH"
      },
      "source": [
        "def get_split(text1, chunk_len = 200, overlap = 50):\n",
        "  l_total = []\n",
        "  l_parcial = []\n",
        "  if len(text1.split())//(chunk_len-overlap) >0:\n",
        "    n = len(text1.split())//(chunk_len-overlap)\n",
        "  else: \n",
        "    n = 1\n",
        "  for w in range(n):\n",
        "    if w == 0:\n",
        "      l_parcial = text1.split()[:chunk_len]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "    else:\n",
        "      l_parcial = text1.split()[w*(chunk_len - overlap):w*(chunk_len - overlap) + 200]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "  return l_total"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-u6mDkbLpTY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "1c45a3f3-b906-4bb0-af1b-4793421248f5"
      },
      "source": [
        "train['text_split'] = train[DATA_COLUMN].apply(get_split)\n",
        "train.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "      <th>len_txt</th>\n",
              "      <th>text_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन ...</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>[@YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@abccare Aditya Birla company fraud 8400 se ru...</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>[@abccare Aditya Birla company fraud 8400 se r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oral health and hygiene market in Ireland is c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1148</td>\n",
              "      <td>[Oral health and hygiene market in Ireland is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The World Health Organization has set the reco...</td>\n",
              "      <td>0</td>\n",
              "      <td>713</td>\n",
              "      <td>[The World Health Organization has set the rec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bismah Malik By\\n\\nExpress News Service\\n\\nBEN...</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>[Bismah Malik By Express News Service BENGALUR...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         text_split\n",
              "0  @YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन ...  ...  [@YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन...\n",
              "1  @abccare Aditya Birla company fraud 8400 se ru...  ...  [@abccare Aditya Birla company fraud 8400 se r...\n",
              "2  Oral health and hygiene market in Ireland is c...  ...  [Oral health and hygiene market in Ireland is ...\n",
              "3  The World Health Organization has set the reco...  ...  [The World Health Organization has set the rec...\n",
              "4  Bismah Malik By\\n\\nExpress News Service\\n\\nBEN...  ...  [Bismah Malik By Express News Service BENGALUR...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Xt9v65FKYj",
        "outputId": "7ca7c2f5-e547-4633-af3b-8bde11cb8d4b"
      },
      "source": [
        "len(train['text_split'][0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zrlehCFUplB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "4bb4d7eb-fa78-4972-e976-ef5fbf1ddd53"
      },
      "source": [
        "val['text_split'] = val[DATA_COLUMN].apply(get_split)\n",
        "val.head(2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "      <th>len_txt</th>\n",
              "      <th>text_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>नई दिल्ली। भारतीय रिजर्व बैंक ऑफ इंडिया ने अहम...</td>\n",
              "      <td>0</td>\n",
              "      <td>250</td>\n",
              "      <td>[नई दिल्ली। भारतीय रिजर्व बैंक ऑफ इंडिया ने अह...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ministry of Finance\\n\\nRevised Issuance Calend...</td>\n",
              "      <td>0</td>\n",
              "      <td>587</td>\n",
              "      <td>[Ministry of Finance Revised Issuance Calendar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...                                         text_split\n",
              "0  नई दिल्ली। भारतीय रिजर्व बैंक ऑफ इंडिया ने अहम...  ...  [नई दिल्ली। भारतीय रिजर्व बैंक ऑफ इंडिया ने अह...\n",
              "1  Ministry of Finance\\n\\nRevised Issuance Calend...  ...  [Ministry of Finance Revised Issuance Calendar...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Av2nX5KFlxZ",
        "outputId": "df859b21-ae71-4799-c01a-2ef26d6293f9"
      },
      "source": [
        "len(train['Text'][0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO8qAqmMFafl",
        "outputId": "b7ed5e51-18d8-4bc6-deb2-fec9bb52e093"
      },
      "source": [
        "len(train['text_split'][0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_zMerj1VGaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827ff2e0-d681-4ef0-e26e-844ea00cfa0c"
      },
      "source": [
        "train_l = []\n",
        "label_l = []\n",
        "index_l =[]\n",
        "for idx,row in train.iterrows():\n",
        "  for l in row['text_split']:\n",
        "    train_l.append(l)\n",
        "    label_l.append(row['Mobile_Tech_Flag'])\n",
        "    index_l.append(idx)\n",
        "len(train_l), len(label_l), len(index_l)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14141, 14141, 14141)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBrXEaxHVNG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326dbf2d-603a-4fe4-c106-3408012dd0db"
      },
      "source": [
        "val_l = []\n",
        "val_label_l = []\n",
        "val_index_l = []\n",
        "for idx,row in val.iterrows():\n",
        "  for l in row['text_split']:\n",
        "    val_l.append(l)\n",
        "    val_label_l.append(row['Mobile_Tech_Flag'])\n",
        "    val_index_l.append(idx)\n",
        "len(val_l), len(val_label_l), len(val_index_l)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3507, 3507, 3507)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu5Sx8Rm0bAj"
      },
      "source": [
        "The final dataset for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mojRk8kWVVB4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4908f066-be23-4e6f-b839-fbe997024be6"
      },
      "source": [
        "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
        "train_df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@abccare Aditya Birla company fraud 8400 se ru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oral health and hygiene market in Ireland is c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>assess Irish consumers’ current dental care ha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will significantly reduce the chances of bigge...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Mobile_Tech_Flag\n",
              "0  @YouthExpressIND: यूनिक डिजाइन के साथ बेहतरीन ...                 1\n",
              "1  @abccare Aditya Birla company fraud 8400 se ru...                 0\n",
              "2  Oral health and hygiene market in Ireland is c...                 0\n",
              "3  assess Irish consumers’ current dental care ha...                 0\n",
              "4  will significantly reduce the chances of bigge...                 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_I-ZbSKVmrZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c37bbe4b-50a7-4245-9f35-7d8222d17e49"
      },
      "source": [
        "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
        "val_df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Mobile_Tech_Flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>नई दिल्ली। भारतीय रिजर्व बैंक ऑफ इंडिया ने अहम...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ministry of Finance Revised Issuance Calendar ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>₹5,000 crore iii) 14 Year for ₹11,000 crore iv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>March 22-26, 2021 20,000 i) FRB ₹4,000 crore i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@BJP4MP @vdsharmabjp @ChouhanShivraj @nstomar ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Mobile_Tech_Flag\n",
              "0  नई दिल्ली। भारतीय रिजर्व बैंक ऑफ इंडिया ने अहम...                 0\n",
              "1  Ministry of Finance Revised Issuance Calendar ...                 0\n",
              "2  ₹5,000 crore iii) 14 Year for ₹11,000 crore iv...                 0\n",
              "3  March 22-26, 2021 20,000 i) FRB ₹4,000 crore i...                 0\n",
              "4  @BJP4MP @vdsharmabjp @ChouhanShivraj @nstomar ...                 1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og08g7DScPtK"
      },
      "source": [
        "# XLMR: Data Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRM4u9Q1LoO1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b9ca6244893e4cbe91853496ad08f1da",
            "922d035525bd4adc80018d454024572e",
            "eff4c239a8064db288bad592489d5964",
            "ec2fe1ced04a4943b245e5c2ef2aaa3a",
            "cfd2fb6a837748a990cb802fc9cfa5e2",
            "77113ee1d86242b797d22ad189d4269e",
            "9b2b5062bfdd42b28a28a63c9e55d5ca",
            "c6633d15966a4aaca3180702112d516f"
          ]
        },
        "outputId": "f3778e0f-4f50-4c97-b4d0-09626c7ba8a7"
      },
      "source": [
        "from transformers import XLMRobertaTokenizer\r\n",
        "\r\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9ca6244893e4cbe91853496ad08f1da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdajkJbxLtYn",
        "outputId": "8590aa84-5f4b-48ea-f63a-9eee10952106"
      },
      "source": [
        "all_tokens = list(tokenizer.get_vocab().keys())\r\n",
        "print(f'This is a vocab of {len(all_tokens)} tokens')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a vocab of 250002 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qINvFK3zLvxK",
        "outputId": "6788f4b0-a751-45bd-d798-429225a37d35"
      },
      "source": [
        "print(tokenizer)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PreTrainedTokenizer(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XJwSmNvLyv5"
      },
      "source": [
        "with open(\"/content/sample_data/vocab.txt\", \"w\") as f:\r\n",
        "   for token in all_tokens:\r\n",
        "       f.write(token + '\\n')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yH9bRHKVMP8",
        "outputId": "e9170a31-176f-4060-8772-77b1c0790ed0"
      },
      "source": [
        "train_df.values.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14141, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CEj_IoUVOwG",
        "outputId": "242f5502-a5b2-4da9-f400-0529d6037fe7"
      },
      "source": [
        "val_df.values.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3507, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMUFGAJWVaRD",
        "outputId": "556dec8b-ad68-4b8d-d2c0-3cc72b639a5f"
      },
      "source": [
        "pd.concat([train_df, val_df]).values.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17648, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCBw32XXMPPM"
      },
      "source": [
        "df_art = pd.concat([train_df, val_df])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvWWgepjL028",
        "outputId": "07f9a2c4-867f-4800-efa3-5e092c0f98bb"
      },
      "source": [
        "# Retrive the first article \r\n",
        "\r\n",
        "text = df_art.iloc[1].Text\r\n",
        "tokens = tokenizer.tokenize(text)\r\n",
        "\r\n",
        "print(f'No of tokens in this article : {len(tokens)}')\r\n",
        "\r\n",
        "print(text)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of tokens in this article : 89\n",
            "@abccare Aditya Birla company fraud 8400 se rupaye mujhse lekar loan approval abhi tak nahin kiya ek Mahina Ho Gaya kisi Garib ka Paisa loot Hain kripya Sarkar se nivedan hai Aditya Birla company ko band karaya jaaye seal kar diya jaaye aur media wale bhi sunte nahin music YouTube https://t.co/XxfsghWgj5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_4qy28bL9Ew",
        "outputId": "9fa56122-b8bf-483d-99b8-9b3c15126d4d"
      },
      "source": [
        "print('First 512 tokens : ')\r\n",
        "print(tokens[:512])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 512 tokens : \n",
            "['▁@', 'ab', 'cca', 're', '▁Adi', 'tya', '▁Bir', 'la', '▁company', '▁fraud', '▁8', '400', '▁se', '▁rupa', 'ye', '▁mujh', 'se', '▁lekar', '▁loan', '▁appro', 'val', '▁a', 'bhi', '▁tak', '▁na', 'hin', '▁kiya', '▁ek', '▁Mah', 'ina', '▁Ho', '▁Gaya', '▁kisi', '▁Gar', 'ib', '▁ka', '▁Pais', 'a', '▁loo', 't', '▁Hain', '▁', 'krip', 'ya', '▁Sarkar', '▁se', '▁ni', 've', 'dan', '▁hai', '▁Adi', 'tya', '▁Bir', 'la', '▁company', '▁ko', '▁band', '▁kara', 'ya', '▁ja', 'aye', '▁seal', '▁kar', '▁diya', '▁ja', 'aye', '▁aur', '▁media', '▁wale', '▁bhi', '▁sunt', 'e', '▁na', 'hin', '▁music', '▁YouTube', '▁https', '://', 't', '.', 'co', '/', 'X', 'x', 'fs', 'gh', 'W', 'gj', '5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhc1yiPSLbak",
        "outputId": "08faa452-ba76-468f-9448-36ec85d8304c"
      },
      "source": [
        "# Main Tokenization here \r\n",
        "input_ids = []\r\n",
        "lengths = []\r\n",
        "\r\n",
        "print('Tokenizing comments.....')\r\n",
        "\r\n",
        "for sen in df_art.Text:\r\n",
        "\r\n",
        "    if(len(input_ids) % 1000 == 0):\r\n",
        "      print(f'Read about {len(input_ids)} article!')\r\n",
        "    \r\n",
        "\r\n",
        "    encoded_sent = tokenizer.encode(\r\n",
        "                            sen,\r\n",
        "                            # max_length = 512,\r\n",
        "                            # return_tensors = 'pt'   \r\n",
        "                            )\r\n",
        "    \r\n",
        "    input_ids.append(encoded_sent)\r\n",
        "    lengths.append(len(encoded_sent))\r\n",
        "\r\n",
        "print('Done!')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing comments.....\n",
            "Read about 0 article!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Read about 1000 article!\n",
            "Read about 2000 article!\n",
            "Read about 3000 article!\n",
            "Read about 4000 article!\n",
            "Read about 5000 article!\n",
            "Read about 6000 article!\n",
            "Read about 7000 article!\n",
            "Read about 8000 article!\n",
            "Read about 9000 article!\n",
            "Read about 10000 article!\n",
            "Read about 11000 article!\n",
            "Read about 12000 article!\n",
            "Read about 13000 article!\n",
            "Read about 14000 article!\n",
            "Read about 15000 article!\n",
            "Read about 16000 article!\n",
            "Read about 17000 article!\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lF21p_KLXvQ",
        "outputId": "f40a0204-37cf-4994-d32d-fc20681a512e"
      },
      "source": [
        "labels = df_art.Mobile_Tech_Flag.to_numpy().astype(int)\r\n",
        "\r\n",
        "print(f'No of mobile_tech labels : {np.sum(labels)}')\r\n",
        "print(f'No of non_mobile_tech labels : {len(labels) - np.sum(labels)}')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of mobile_tech labels : 4351\n",
            "No of non_mobile_tech labels : 13297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0ROxgbqOfxQ",
        "outputId": "5b3302fc-0074-48b4-c47c-c089aaef0d6f"
      },
      "source": [
        "print(f'Min length of tokens : {min(lengths)}')\r\n",
        "print(f'Max length of tokens : {max(lengths)}')\r\n",
        "print(f'Mean length of tokens : {np.mean(lengths)}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min length of tokens : 6\n",
            "Max length of tokens : 1073\n",
            "Mean length of tokens : 239.29357434270173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfhC73VaLXta",
        "outputId": "95cbb8a6-6889-4553-86b6-e31b852613b0"
      },
      "source": [
        "print(f'Min length of tokens : {min(lengths)}')\r\n",
        "print(f'Max length of tokens : {max(lengths)}')\r\n",
        "print(f'Mean length of tokens : {np.mean(lengths)}')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min length of tokens : 6\n",
            "Max length of tokens : 1073\n",
            "Mean length of tokens : 239.29357434270173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TTszxceLXro",
        "outputId": "535915f6-4ac2-4e5d-c251-790861fd76a7"
      },
      "source": [
        "temp = []\r\n",
        "\r\n",
        "for i in lengths:\r\n",
        "    if(i > 833):\r\n",
        "        temp.append(i)\r\n",
        "print(len(temp))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "WNEyLeMDLXpW",
        "outputId": "86b5fd8e-7a1a-4fb6-d2dd-fe6e3a2b7a5f"
      },
      "source": [
        "#Plotting the data for knowing distributions of length if tokens!\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "sns.set(style = 'dark')\r\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\r\n",
        "new_lengths = [min(l,2000) for l in lengths]\r\n",
        "\r\n",
        "sns.distplot(new_lengths,kde=False)\r\n",
        "\r\n",
        "plt.title('Article token length dist.')\r\n",
        "plt.xlabel('Article Length')\r\n",
        "plt.ylabel('no of articles')\r\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQdmo3EhUluy"
      },
      "source": [
        "# Truncating to 512 for now (other wise use chunking for giving sentence length)\r\n",
        "\r\n",
        "from keras.preprocessing.sequence import  pad_sequences\r\n",
        "\r\n",
        "MAX_LEN = 512\r\n",
        "\r\n",
        "input_ids = pad_sequences(input_ids, maxlen = MAX_LEN, dtype = \"long\", value=0, \r\n",
        "                          truncating=\"post\", padding=\"post\")\r\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKVXctzXUlz6",
        "outputId": "01b7f373-99aa-45c1-8068-20cfefa9189e"
      },
      "source": [
        "print(input_ids.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17648, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHqQ_nhzUl5k"
      },
      "source": [
        "# Attention Mask\r\n",
        "attention_masks = []\r\n",
        "\r\n",
        "for sent in input_ids:\r\n",
        "    # set mask to 0 if token_id is 0 (becoz its padding) and vice versa\r\n",
        "    attn_mask = [int(token_id > 0) for token_id in sent]\r\n",
        "    attention_masks.append(attn_mask)\r\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bPP3fsqUl-3"
      },
      "source": [
        "# Now we split the data into 90 percent for training and 10 percent for testing \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size = 0.1, random_state = 42)\r\n",
        "train_masks, val_masks = train_test_split(attention_masks, test_size = 0.1, random_state = 42)\r\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NpA052qUmFe"
      },
      "source": [
        "train_inputs = t.tensor(train_inputs)\r\n",
        "val_inputs = t.tensor(val_inputs)\r\n",
        "\r\n",
        "train_labels = t.tensor(train_labels )\r\n",
        "val_labels = t.tensor(val_labels)\r\n",
        "\r\n",
        "train_masks = t.tensor(train_masks)\r\n",
        "val_masks = t.tensor(val_masks)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAp-Q_QLUmJF"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "\r\n",
        "batch_size = 8\r\n",
        "\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_loader = DataLoader(train_data, batch_size = batch_size, sampler = train_sampler)\r\n",
        "\r\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\r\n",
        "val_sampler = RandomSampler(val_data)\r\n",
        "val_loader = DataLoader(val_data, batch_size = batch_size, sampler = val_sampler)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzVEeH8rUmPH"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDjj9yzNUmTr"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-ZjNulJUmX6"
      },
      "source": [
        ""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoIt5AHadACM"
      },
      "source": [
        "# XLMR: Loading the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-DuwJRkULUs"
      },
      "source": [
        "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "13847a29b48d46b98258c21cd36f978f",
            "265f7ad895c14c4ba4c1fde62f88fad6",
            "e4c6a0894a704cc981b3837bfa477320",
            "930e6541026944639ca65e772b5d7e49",
            "6e8d44ab74114b9bbb29ebf053e3fcdb",
            "3b3e8ae16773437188b54a78b778b94f",
            "9eead7f3d1fd49858989c1b54483361b",
            "5643b7a7e3ff4aebb0940f9c2d8bfd8e",
            "9cfd3c81a8564523882abb1ef8e10ffc",
            "88f90d64735d47f19084c4cbe5bacb06",
            "b19b9d38d5dd4b8b8506c239be282b72",
            "a25b4924f82d470a99db9dce54cfecb4",
            "508d81e0effc4d6890f5357e3bd1b254",
            "13908ddf7b584f0392298da22aee9f68",
            "5eb9450267cc4c6a8ddc06acbd7c7fb0",
            "9f8badd9e01e4ded9bac62841fa67c54"
          ]
        },
        "id": "uasJcRJwUN_2",
        "outputId": "94530fb1-9966-4bcc-d164-29f3bb7f3352"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification, AdamW, XLMRobertaConfig\r\n",
        "\r\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\r\n",
        "        \"xlm-roberta-base\",\r\n",
        "        num_labels = 2,\r\n",
        "        output_attentions = False,\r\n",
        "        output_hidden_states = False,\r\n",
        ")\r\n",
        "\r\n",
        "model.cuda()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13847a29b48d46b98258c21cd36f978f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cfd3c81a8564523882abb1ef8e10ffc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yjXhBxFZU-D"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNZyihB7YqpO",
        "outputId": "f5df5562-4ca4-4a0c-9803-c5726ac5e703"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/My Drive/Inter-IIT/article(chunked)+tweets_model_8epochs.bin'))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ2uDagQUOEB"
      },
      "source": [
        "# optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1rkXoyzUQf5"
      },
      "source": [
        "# from transformers import get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "# # num epochs\r\n",
        "# epochs = 10\r\n",
        "\r\n",
        "# # Total training steps is basically  no. of batches * total epochs \r\n",
        "# total_training_steps = len(train_loader)*epochs\r\n",
        "\r\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer,\r\n",
        "#                                             num_warmup_steps = 0,\r\n",
        "#                                             num_training_steps = total_training_steps)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzwVCiwwUQkX"
      },
      "source": [
        "# def flat_accuracy(preds, labels):\r\n",
        "#     pred_flat = np.argmax(preds, axis = 1).flatten()\r\n",
        "#     labels_flat = labels.flatten()\r\n",
        "#     # print(pred_flat)\r\n",
        "#     return np.sum(pred_flat == labels_flat)/ len(labels_flat)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6R4B3ltUTai"
      },
      "source": [
        "# import time \r\n",
        "# import datetime\r\n",
        "\r\n",
        "# def format_time(elapsed):\r\n",
        "\r\n",
        "#     elapsed_rounded = int(round(elapsed))\r\n",
        "\r\n",
        "#     return str(datetime.timedelta(seconds = elapsed_rounded)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJGiV2dmgpYh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF1BdtRjgflV"
      },
      "source": [
        "# for step, batch in enumerate(train_loader):\r\n",
        "#   optimizer.zero_grad()\r\n",
        "#   input_ids = batch[0].to(device)    # The main training data\r\n",
        "#   input_ids = input_ids[0].unsqueeze(0)\r\n",
        "#   attention_mask = batch[1].to(device)  # The input masks for padding\r\n",
        "#   attention_mask = attention_mask[0].unsqueeze(0)\r\n",
        "#   print(type(input_ids),input_ids.shape,type(attention_mask) ,attention_mask.shape)\r\n",
        "\r\n",
        "#   # Forward Pass\r\n",
        "#   outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\r\n",
        "#   loss = outputs[0]\r\n",
        "#   total_loss += loss.item()"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIQfeOhzUTeM"
      },
      "source": [
        "# from tqdm import tqdm\r\n",
        "\r\n",
        "# loss_values = []\r\n",
        "\r\n",
        "# for i in range(0, epochs):\r\n",
        "#     print(\"\")\r\n",
        "#     print(f\"======= Epoch {i + 1}/{epochs} =======\")\r\n",
        "#     print(\"Training.....\")\r\n",
        "\r\n",
        "#     total_loss = 0 \r\n",
        "#     model.train()\r\n",
        "    \r\n",
        "#     for step, batch in enumerate(tqdm(train_loader)):\r\n",
        "#         optimizer.zero_grad()\r\n",
        "#         input_ids = batch[0].to(device)    # The main training data\r\n",
        "#         attention_mask = batch[1].to(device)  # The input masks for padding\r\n",
        "#         labels = batch[2].to(device)        # The labels \r\n",
        "        \r\n",
        "#         # Forward Pass\r\n",
        "#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\r\n",
        "#         loss = outputs[0]\r\n",
        "#         total_loss += loss.item()\r\n",
        "        \r\n",
        "#         # Backward Pass \r\n",
        "#         loss.backward()\r\n",
        "#         t.nn.utils.clip_grad_norm_(model.parameters(),1.0)\r\n",
        "#         optimizer.step()\r\n",
        "#         scheduler.step()\r\n",
        "\r\n",
        "#     avg_loss = (total_loss / len(train_loader))\r\n",
        "#     print(f'The average Training Loss after {i + 1} epochs : {avg_loss}')\r\n",
        "#     loss_values.append(avg_loss)\r\n",
        "\r\n",
        "#     ###### Validation from here #######\r\n",
        "#     print(\"Validating.....\")\r\n",
        "#     model.eval()\r\n",
        "#     eval_loss = 0\r\n",
        "#     eval_accuracy = 0\r\n",
        "#     nb_steps = 0\r\n",
        "\r\n",
        "#     for step,batch in enumerate(tqdm(val_loader)):\r\n",
        "#         input_ids = batch[0].to(device)    # The main training data\r\n",
        "#         attention_mask = batch[1].to(device)  # The input masks for padding\r\n",
        "#         labels = batch[2].to(device)        # The labels \r\n",
        "\r\n",
        "#         with t.no_grad():\r\n",
        "#             outputs = model(input_ids, attention_mask=attention_mask)\r\n",
        "\r\n",
        "#         logits = outputs[0]\r\n",
        "#         logits = logits.detach().cpu().numpy()\r\n",
        "#         label_ids = labels.to('cpu').numpy()\r\n",
        "\r\n",
        "#         tmp_accuracy = flat_accuracy(logits,label_ids)\r\n",
        "#         eval_accuracy += tmp_accuracy\r\n",
        "#         nb_steps += 1\r\n",
        "\r\n",
        "#     print(f'The average Accuracy after validation : {(eval_accuracy)/(nb_steps)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czkgwWMcUOHj"
      },
      "source": [
        "# # Plot the training loss\r\n",
        "# sns.set(style = 'darkgrid')\r\n",
        "# plt.rcParams[\"figure.figsize\"] = (12,6)\r\n",
        "\r\n",
        "# plt.plot(loss_values,'b-o')\r\n",
        "\r\n",
        "# plt.title('Training Loss')\r\n",
        "# plt.xlabel('Epochs')\r\n",
        "# plt.ylabel('Train loss')\r\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdJ6O6YrZlet"
      },
      "source": [
        "#Validation on the val split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYsux88icpwW"
      },
      "source": [
        "batch_size = 1\r\n",
        "val_loader = DataLoader(val_data, batch_size = batch_size, sampler = val_sampler)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bayxinPzcppX",
        "outputId": "31f7686a-6f08-4735-aee5-620beefded19"
      },
      "source": [
        "type(val_loader)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxoXUOVEcvWU"
      },
      "source": [
        "# printing a classification report \r\n",
        "\r\n",
        "model.eval()\r\n",
        "y_true = []\r\n",
        "y_pred = []\r\n",
        "eval_loss = 0\r\n",
        "eval_accuracy = 0\r\n",
        "nb_steps = 0\r\n",
        "\r\n",
        "for batch in val_loader:\r\n",
        "    input_ids = batch[0].to(device)    # The main training data\r\n",
        "    attention_mask = batch[1].to(device)  # The input masks for padding\r\n",
        "    labels = batch[2].to(device)        # The labels \r\n",
        "\r\n",
        "    with t.no_grad():\r\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\r\n",
        "\r\n",
        "    logits = outputs[0]\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    label_ids = labels.to('cpu').numpy()\r\n",
        "    pred_flat = np.argmax(logits, axis = 1).flatten()\r\n",
        "    labels_flat = label_ids.flatten()\r\n",
        "    \r\n",
        "    y_pred.append(pred_flat[0])\r\n",
        "    y_true.append(labels_flat[0])\r\n",
        "    # print(pred_flat,labels_flat)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrM0lY_HcxXN",
        "outputId": "e16d16f3-87e6-4f6d-f1ba-42a12ba792a5"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "target_names = ['Other', 'Mobile_Tech']\r\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Other       0.97      0.98      0.97      1344\n",
            " Mobile_Tech       0.93      0.90      0.92       421\n",
            "\n",
            "    accuracy                           0.96      1765\n",
            "   macro avg       0.95      0.94      0.94      1765\n",
            "weighted avg       0.96      0.96      0.96      1765\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZQWBmr3ULPP"
      },
      "source": [
        "# torch.save(model.state_dict(),'/content/drive/My Drive/Inter-IIT/article(chunked)+tweets_model_8epochs.bin' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e75wsPw6Zyvb"
      },
      "source": [
        "#Testing on custom input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT4D98wjpNCt",
        "outputId": "965a7130-95c6-42cd-ad07-c763d83f5576"
      },
      "source": [
        "df_art.iloc[:].values.shape"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17648, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPmyF8QnaZ9d"
      },
      "source": [
        "#Choose the index of the dataset entry to test on\r\n",
        "i = 10"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6VVdk1YaVH0"
      },
      "source": [
        "text = df_art.iloc[i].Text\r\n"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "nh1bmKGeoYea",
        "outputId": "02ad26e3-3c87-435b-8d88-b96b3d0ad188"
      },
      "source": [
        " df_art.iloc[i].Text"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The results showed that bleeding of the gums on gentle probing, or gingival bleeding tendency, and also bleeding in the eye, or retinal hemorrhaging, were associated with low vitamin C levels in the bloodstream. And, the researchers found that increasing daily intake of vitamin C in those people with low vitamin C plasma levels helped to reverse these bleeding issues. Of potential relevance, says Hujoel, who is also an adjunct professor of epidemiology in the UW School of Public Health, both a gum bleeding tendency and retinal bleeding could be a sign of general trouble in one's microvascular system, of a microvascular bleeding tendency in the brain, heart and kidneys. The study does not imply that successful reversing of an increased gingival bleeding tendency with vitamin C will prevent strokes or other serious health outcomes, Hujoel stresses. However, the results do suggest that vitamin C recommendations designed primarily to protect against scurvy — a deadly disease caused by extremely low vitamin C levels — are too low, and that such a low vitamin C intake can lead to a bleeding tendency, which should not be treated with dental floss. Consequently, Hujoel does recommend people attempt to keep an eye on\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6xtgujPoZ88",
        "outputId": "11df3c73-3cf5-4b4a-fdc6-45da5a6e957e"
      },
      "source": [
        " df_art.iloc[i].Mobile_Tech_Flag"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-q6zUNqoPRB"
      },
      "source": [
        "#Uncomment this to send custom text\r\n",
        "\r\n",
        "#text = \"My device is laggy nowadays, more precisely, since a month ago!\""
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOcDevWLoOWz"
      },
      "source": [
        "tokens = tokenizer.tokenize(text)"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lb6R05oaklk",
        "outputId": "e25283b1-3a18-4440-e9ce-641dd05f2cd4"
      },
      "source": [
        "tokens"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁The',\n",
              " '▁results',\n",
              " '▁showed',\n",
              " '▁that',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁of',\n",
              " '▁the',\n",
              " '▁gum',\n",
              " 's',\n",
              " '▁on',\n",
              " '▁gent',\n",
              " 'le',\n",
              " '▁prob',\n",
              " 'ing',\n",
              " ',',\n",
              " '▁or',\n",
              " '▁ging',\n",
              " 'ival',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁tende',\n",
              " 'ncy',\n",
              " ',',\n",
              " '▁and',\n",
              " '▁also',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁in',\n",
              " '▁the',\n",
              " '▁eye',\n",
              " ',',\n",
              " '▁or',\n",
              " '▁retin',\n",
              " 'al',\n",
              " '▁hem',\n",
              " 'or',\n",
              " 'r',\n",
              " 'ha',\n",
              " 'ging',\n",
              " ',',\n",
              " '▁were',\n",
              " '▁associated',\n",
              " '▁with',\n",
              " '▁low',\n",
              " '▁vitamin',\n",
              " '▁C',\n",
              " '▁levels',\n",
              " '▁in',\n",
              " '▁the',\n",
              " '▁blood',\n",
              " 'stream',\n",
              " '.',\n",
              " '▁And',\n",
              " ',',\n",
              " '▁the',\n",
              " '▁research',\n",
              " 'ers',\n",
              " '▁found',\n",
              " '▁that',\n",
              " '▁increasing',\n",
              " '▁daily',\n",
              " '▁in',\n",
              " 'take',\n",
              " '▁of',\n",
              " '▁vitamin',\n",
              " '▁C',\n",
              " '▁in',\n",
              " '▁those',\n",
              " '▁people',\n",
              " '▁with',\n",
              " '▁low',\n",
              " '▁vitamin',\n",
              " '▁C',\n",
              " '▁plasma',\n",
              " '▁levels',\n",
              " '▁helped',\n",
              " '▁to',\n",
              " '▁rever',\n",
              " 'se',\n",
              " '▁these',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁issues',\n",
              " '.',\n",
              " '▁Of',\n",
              " '▁potential',\n",
              " '▁relevan',\n",
              " 'ce',\n",
              " ',',\n",
              " '▁says',\n",
              " '▁Hu',\n",
              " 'jo',\n",
              " 'el',\n",
              " ',',\n",
              " '▁who',\n",
              " '▁is',\n",
              " '▁also',\n",
              " '▁an',\n",
              " '▁ad',\n",
              " 'jun',\n",
              " 'ct',\n",
              " '▁professor',\n",
              " '▁of',\n",
              " '▁epidemi',\n",
              " 'ology',\n",
              " '▁in',\n",
              " '▁the',\n",
              " '▁U',\n",
              " 'W',\n",
              " '▁School',\n",
              " '▁of',\n",
              " '▁Public',\n",
              " '▁Health',\n",
              " ',',\n",
              " '▁both',\n",
              " '▁a',\n",
              " '▁gum',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁tende',\n",
              " 'ncy',\n",
              " '▁and',\n",
              " '▁retin',\n",
              " 'al',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁could',\n",
              " '▁be',\n",
              " '▁a',\n",
              " '▁sign',\n",
              " '▁of',\n",
              " '▁general',\n",
              " '▁trouble',\n",
              " '▁in',\n",
              " '▁one',\n",
              " \"'\",\n",
              " 's',\n",
              " '▁micro',\n",
              " 'vas',\n",
              " 'cular',\n",
              " '▁system',\n",
              " ',',\n",
              " '▁of',\n",
              " '▁a',\n",
              " '▁micro',\n",
              " 'vas',\n",
              " 'cular',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁tende',\n",
              " 'ncy',\n",
              " '▁in',\n",
              " '▁the',\n",
              " '▁brain',\n",
              " ',',\n",
              " '▁heart',\n",
              " '▁and',\n",
              " '▁ki',\n",
              " 'dne',\n",
              " 'ys',\n",
              " '.',\n",
              " '▁The',\n",
              " '▁study',\n",
              " '▁does',\n",
              " '▁not',\n",
              " '▁imp',\n",
              " 'ly',\n",
              " '▁that',\n",
              " '▁successful',\n",
              " '▁rever',\n",
              " 'sing',\n",
              " '▁of',\n",
              " '▁an',\n",
              " '▁increased',\n",
              " '▁ging',\n",
              " 'ival',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁tende',\n",
              " 'ncy',\n",
              " '▁with',\n",
              " '▁vitamin',\n",
              " '▁C',\n",
              " '▁will',\n",
              " '▁prevent',\n",
              " '▁stroke',\n",
              " 's',\n",
              " '▁or',\n",
              " '▁other',\n",
              " '▁serious',\n",
              " '▁health',\n",
              " '▁outcome',\n",
              " 's',\n",
              " ',',\n",
              " '▁Hu',\n",
              " 'jo',\n",
              " 'el',\n",
              " '▁stress',\n",
              " 'es',\n",
              " '.',\n",
              " '▁However',\n",
              " ',',\n",
              " '▁the',\n",
              " '▁results',\n",
              " '▁do',\n",
              " '▁suggest',\n",
              " '▁that',\n",
              " '▁vitamin',\n",
              " '▁C',\n",
              " '▁recommendations',\n",
              " '▁designed',\n",
              " '▁primari',\n",
              " 'ly',\n",
              " '▁to',\n",
              " '▁protect',\n",
              " '▁against',\n",
              " '▁s',\n",
              " 'cur',\n",
              " 'vy',\n",
              " '▁—',\n",
              " '▁a',\n",
              " '▁dead',\n",
              " 'ly',\n",
              " '▁disease',\n",
              " '▁caused',\n",
              " '▁by',\n",
              " '▁extremely',\n",
              " '▁low',\n",
              " '▁vitamin',\n",
              " '▁C',\n",
              " '▁levels',\n",
              " '▁—',\n",
              " '▁are',\n",
              " '▁too',\n",
              " '▁low',\n",
              " ',',\n",
              " '▁and',\n",
              " '▁that',\n",
              " '▁such',\n",
              " '▁a',\n",
              " '▁low',\n",
              " '▁vitamin',\n",
              " '▁C',\n",
              " '▁in',\n",
              " 'take',\n",
              " '▁can',\n",
              " '▁lead',\n",
              " '▁to',\n",
              " '▁a',\n",
              " '▁ble',\n",
              " 'ed',\n",
              " 'ing',\n",
              " '▁tende',\n",
              " 'ncy',\n",
              " ',',\n",
              " '▁which',\n",
              " '▁should',\n",
              " '▁not',\n",
              " '▁be',\n",
              " '▁treated',\n",
              " '▁with',\n",
              " '▁dental',\n",
              " '▁flo',\n",
              " 's',\n",
              " 's',\n",
              " '.',\n",
              " '▁Con',\n",
              " 'se',\n",
              " 'quen',\n",
              " 't',\n",
              " 'ly',\n",
              " ',',\n",
              " '▁Hu',\n",
              " 'jo',\n",
              " 'el',\n",
              " '▁does',\n",
              " '▁recommend',\n",
              " '▁people',\n",
              " '▁attempt',\n",
              " '▁to',\n",
              " '▁keep',\n",
              " '▁an',\n",
              " '▁eye',\n",
              " '▁on']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWsj0nWJbHzE"
      },
      "source": [
        "encoded_sent = tokenizer.encode(\r\n",
        "                            tokens,\r\n",
        "                            # max_length = 512,\r\n",
        "                            # return_tensors = 'pt'   \r\n",
        "                            )"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5TKApCabLSn",
        "outputId": "8899f213-698a-4562-e7a4-123b6aebb930"
      },
      "source": [
        "encoded_sent"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 581,\n",
              " 50339,\n",
              " 168360,\n",
              " 450,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 111,\n",
              " 70,\n",
              " 29204,\n",
              " 7,\n",
              " 98,\n",
              " 21507,\n",
              " 133,\n",
              " 43011,\n",
              " 214,\n",
              " 4,\n",
              " 707,\n",
              " 21859,\n",
              " 47898,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 72201,\n",
              " 27771,\n",
              " 4,\n",
              " 136,\n",
              " 2843,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 23,\n",
              " 70,\n",
              " 36298,\n",
              " 4,\n",
              " 707,\n",
              " 119256,\n",
              " 289,\n",
              " 2360,\n",
              " 748,\n",
              " 42,\n",
              " 528,\n",
              " 9966,\n",
              " 4,\n",
              " 3542,\n",
              " 137272,\n",
              " 678,\n",
              " 27226,\n",
              " 13864,\n",
              " 313,\n",
              " 90926,\n",
              " 23,\n",
              " 70,\n",
              " 59714,\n",
              " 86429,\n",
              " 5,\n",
              " 3493,\n",
              " 4,\n",
              " 70,\n",
              " 25188,\n",
              " 1314,\n",
              " 14037,\n",
              " 450,\n",
              " 118055,\n",
              " 31815,\n",
              " 23,\n",
              " 78219,\n",
              " 111,\n",
              " 13864,\n",
              " 313,\n",
              " 23,\n",
              " 8382,\n",
              " 3395,\n",
              " 678,\n",
              " 27226,\n",
              " 13864,\n",
              " 313,\n",
              " 80796,\n",
              " 90926,\n",
              " 104902,\n",
              " 47,\n",
              " 39531,\n",
              " 184,\n",
              " 6097,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 37348,\n",
              " 5,\n",
              " 6619,\n",
              " 38516,\n",
              " 89515,\n",
              " 329,\n",
              " 4,\n",
              " 17378,\n",
              " 7674,\n",
              " 513,\n",
              " 583,\n",
              " 4,\n",
              " 2750,\n",
              " 83,\n",
              " 2843,\n",
              " 142,\n",
              " 606,\n",
              " 17043,\n",
              " 15390,\n",
              " 16030,\n",
              " 111,\n",
              " 83063,\n",
              " 25443,\n",
              " 23,\n",
              " 70,\n",
              " 345,\n",
              " 1456,\n",
              " 19188,\n",
              " 111,\n",
              " 16934,\n",
              " 19102,\n",
              " 4,\n",
              " 15044,\n",
              " 10,\n",
              " 29204,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 72201,\n",
              " 27771,\n",
              " 136,\n",
              " 119256,\n",
              " 289,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 5809,\n",
              " 186,\n",
              " 10,\n",
              " 24092,\n",
              " 111,\n",
              " 4537,\n",
              " 63134,\n",
              " 23,\n",
              " 1632,\n",
              " 25,\n",
              " 7,\n",
              " 11948,\n",
              " 4079,\n",
              " 25667,\n",
              " 5426,\n",
              " 4,\n",
              " 111,\n",
              " 10,\n",
              " 11948,\n",
              " 4079,\n",
              " 25667,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 72201,\n",
              " 27771,\n",
              " 23,\n",
              " 70,\n",
              " 78574,\n",
              " 4,\n",
              " 26498,\n",
              " 136,\n",
              " 200,\n",
              " 10952,\n",
              " 4778,\n",
              " 5,\n",
              " 581,\n",
              " 35187,\n",
              " 14602,\n",
              " 959,\n",
              " 21980,\n",
              " 538,\n",
              " 450,\n",
              " 65771,\n",
              " 39531,\n",
              " 6953,\n",
              " 111,\n",
              " 142,\n",
              " 124735,\n",
              " 21859,\n",
              " 47898,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 72201,\n",
              " 27771,\n",
              " 678,\n",
              " 13864,\n",
              " 313,\n",
              " 1221,\n",
              " 56282,\n",
              " 120472,\n",
              " 7,\n",
              " 707,\n",
              " 3789,\n",
              " 85583,\n",
              " 16227,\n",
              " 184345,\n",
              " 7,\n",
              " 4,\n",
              " 7674,\n",
              " 513,\n",
              " 583,\n",
              " 11405,\n",
              " 90,\n",
              " 5,\n",
              " 33306,\n",
              " 4,\n",
              " 70,\n",
              " 50339,\n",
              " 54,\n",
              " 42459,\n",
              " 450,\n",
              " 13864,\n",
              " 313,\n",
              " 209236,\n",
              " 82775,\n",
              " 102917,\n",
              " 538,\n",
              " 47,\n",
              " 59959,\n",
              " 26548,\n",
              " 91,\n",
              " 16820,\n",
              " 3033,\n",
              " 292,\n",
              " 10,\n",
              " 103494,\n",
              " 538,\n",
              " 70997,\n",
              " 143434,\n",
              " 390,\n",
              " 111531,\n",
              " 27226,\n",
              " 13864,\n",
              " 313,\n",
              " 90926,\n",
              " 292,\n",
              " 621,\n",
              " 5792,\n",
              " 27226,\n",
              " 4,\n",
              " 136,\n",
              " 450,\n",
              " 6044,\n",
              " 10,\n",
              " 27226,\n",
              " 13864,\n",
              " 313,\n",
              " 23,\n",
              " 78219,\n",
              " 831,\n",
              " 37105,\n",
              " 47,\n",
              " 10,\n",
              " 2586,\n",
              " 297,\n",
              " 214,\n",
              " 72201,\n",
              " 27771,\n",
              " 4,\n",
              " 3129,\n",
              " 5608,\n",
              " 959,\n",
              " 186,\n",
              " 191607,\n",
              " 678,\n",
              " 130546,\n",
              " 21917,\n",
              " 7,\n",
              " 7,\n",
              " 5,\n",
              " 1657,\n",
              " 184,\n",
              " 26513,\n",
              " 18,\n",
              " 538,\n",
              " 4,\n",
              " 7674,\n",
              " 513,\n",
              " 583,\n",
              " 14602,\n",
              " 67330,\n",
              " 3395,\n",
              " 81887,\n",
              " 47,\n",
              " 13695,\n",
              " 142,\n",
              " 36298,\n",
              " 98,\n",
              " 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLCUJPbsck-A"
      },
      "source": [
        ""
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VGL6ccPaVDk"
      },
      "source": [
        "#Padding the input sequence to be of length 512 \r\n",
        "'''\r\n",
        "this is implemented to handle the cases with tokens in the sentence less that 512, for example, a sentence might be short, \r\n",
        "having only 200 tokens (for instance)(note that the words in the sentence are >200)\r\n",
        "\r\n",
        "the transformer in usage takes token length of exactly 512, hence, the remaining 512-200=312 tokens would be filled with '0' value,\r\n",
        "as seen below in the attribute 'value=0'\r\n",
        "\r\n",
        "'''\r\n",
        "MAX_LEN = 512\r\n",
        "\r\n",
        "input_ids = pad_sequences([encoded_sent], maxlen = MAX_LEN, dtype = \"long\", value=0, \r\n",
        "                          truncating=\"post\", padding=\"post\")\r\n"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se0EMrdxaU8Q",
        "outputId": "89bbddf3-f1ae-4fb1-9041-e2658d53d396"
      },
      "source": [
        "t.Tensor(input_ids)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 5.8100e+02, 5.0339e+04, 1.6836e+05, 4.5000e+02, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 1.1100e+02, 7.0000e+01, 2.9204e+04, 7.0000e+00,\n",
              "         9.8000e+01, 2.1507e+04, 1.3300e+02, 4.3011e+04, 2.1400e+02, 4.0000e+00,\n",
              "         7.0700e+02, 2.1859e+04, 4.7898e+04, 2.5860e+03, 2.9700e+02, 2.1400e+02,\n",
              "         7.2201e+04, 2.7771e+04, 4.0000e+00, 1.3600e+02, 2.8430e+03, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 2.3000e+01, 7.0000e+01, 3.6298e+04, 4.0000e+00,\n",
              "         7.0700e+02, 1.1926e+05, 2.8900e+02, 2.3600e+03, 7.4800e+02, 4.2000e+01,\n",
              "         5.2800e+02, 9.9660e+03, 4.0000e+00, 3.5420e+03, 1.3727e+05, 6.7800e+02,\n",
              "         2.7226e+04, 1.3864e+04, 3.1300e+02, 9.0926e+04, 2.3000e+01, 7.0000e+01,\n",
              "         5.9714e+04, 8.6429e+04, 5.0000e+00, 3.4930e+03, 4.0000e+00, 7.0000e+01,\n",
              "         2.5188e+04, 1.3140e+03, 1.4037e+04, 4.5000e+02, 1.1806e+05, 3.1815e+04,\n",
              "         2.3000e+01, 7.8219e+04, 1.1100e+02, 1.3864e+04, 3.1300e+02, 2.3000e+01,\n",
              "         8.3820e+03, 3.3950e+03, 6.7800e+02, 2.7226e+04, 1.3864e+04, 3.1300e+02,\n",
              "         8.0796e+04, 9.0926e+04, 1.0490e+05, 4.7000e+01, 3.9531e+04, 1.8400e+02,\n",
              "         6.0970e+03, 2.5860e+03, 2.9700e+02, 2.1400e+02, 3.7348e+04, 5.0000e+00,\n",
              "         6.6190e+03, 3.8516e+04, 8.9515e+04, 3.2900e+02, 4.0000e+00, 1.7378e+04,\n",
              "         7.6740e+03, 5.1300e+02, 5.8300e+02, 4.0000e+00, 2.7500e+03, 8.3000e+01,\n",
              "         2.8430e+03, 1.4200e+02, 6.0600e+02, 1.7043e+04, 1.5390e+04, 1.6030e+04,\n",
              "         1.1100e+02, 8.3063e+04, 2.5443e+04, 2.3000e+01, 7.0000e+01, 3.4500e+02,\n",
              "         1.4560e+03, 1.9188e+04, 1.1100e+02, 1.6934e+04, 1.9102e+04, 4.0000e+00,\n",
              "         1.5044e+04, 1.0000e+01, 2.9204e+04, 2.5860e+03, 2.9700e+02, 2.1400e+02,\n",
              "         7.2201e+04, 2.7771e+04, 1.3600e+02, 1.1926e+05, 2.8900e+02, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 5.8090e+03, 1.8600e+02, 1.0000e+01, 2.4092e+04,\n",
              "         1.1100e+02, 4.5370e+03, 6.3134e+04, 2.3000e+01, 1.6320e+03, 2.5000e+01,\n",
              "         7.0000e+00, 1.1948e+04, 4.0790e+03, 2.5667e+04, 5.4260e+03, 4.0000e+00,\n",
              "         1.1100e+02, 1.0000e+01, 1.1948e+04, 4.0790e+03, 2.5667e+04, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 7.2201e+04, 2.7771e+04, 2.3000e+01, 7.0000e+01,\n",
              "         7.8574e+04, 4.0000e+00, 2.6498e+04, 1.3600e+02, 2.0000e+02, 1.0952e+04,\n",
              "         4.7780e+03, 5.0000e+00, 5.8100e+02, 3.5187e+04, 1.4602e+04, 9.5900e+02,\n",
              "         2.1980e+04, 5.3800e+02, 4.5000e+02, 6.5771e+04, 3.9531e+04, 6.9530e+03,\n",
              "         1.1100e+02, 1.4200e+02, 1.2474e+05, 2.1859e+04, 4.7898e+04, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 7.2201e+04, 2.7771e+04, 6.7800e+02, 1.3864e+04,\n",
              "         3.1300e+02, 1.2210e+03, 5.6282e+04, 1.2047e+05, 7.0000e+00, 7.0700e+02,\n",
              "         3.7890e+03, 8.5583e+04, 1.6227e+04, 1.8434e+05, 7.0000e+00, 4.0000e+00,\n",
              "         7.6740e+03, 5.1300e+02, 5.8300e+02, 1.1405e+04, 9.0000e+01, 5.0000e+00,\n",
              "         3.3306e+04, 4.0000e+00, 7.0000e+01, 5.0339e+04, 5.4000e+01, 4.2459e+04,\n",
              "         4.5000e+02, 1.3864e+04, 3.1300e+02, 2.0924e+05, 8.2775e+04, 1.0292e+05,\n",
              "         5.3800e+02, 4.7000e+01, 5.9959e+04, 2.6548e+04, 9.1000e+01, 1.6820e+04,\n",
              "         3.0330e+03, 2.9200e+02, 1.0000e+01, 1.0349e+05, 5.3800e+02, 7.0997e+04,\n",
              "         1.4343e+05, 3.9000e+02, 1.1153e+05, 2.7226e+04, 1.3864e+04, 3.1300e+02,\n",
              "         9.0926e+04, 2.9200e+02, 6.2100e+02, 5.7920e+03, 2.7226e+04, 4.0000e+00,\n",
              "         1.3600e+02, 4.5000e+02, 6.0440e+03, 1.0000e+01, 2.7226e+04, 1.3864e+04,\n",
              "         3.1300e+02, 2.3000e+01, 7.8219e+04, 8.3100e+02, 3.7105e+04, 4.7000e+01,\n",
              "         1.0000e+01, 2.5860e+03, 2.9700e+02, 2.1400e+02, 7.2201e+04, 2.7771e+04,\n",
              "         4.0000e+00, 3.1290e+03, 5.6080e+03, 9.5900e+02, 1.8600e+02, 1.9161e+05,\n",
              "         6.7800e+02, 1.3055e+05, 2.1917e+04, 7.0000e+00, 7.0000e+00, 5.0000e+00,\n",
              "         1.6570e+03, 1.8400e+02, 2.6513e+04, 1.8000e+01, 5.3800e+02, 4.0000e+00,\n",
              "         7.6740e+03, 5.1300e+02, 5.8300e+02, 1.4602e+04, 6.7330e+04, 3.3950e+03,\n",
              "         8.1887e+04, 4.7000e+01, 1.3695e+04, 1.4200e+02, 3.6298e+04, 9.8000e+01,\n",
              "         2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g9UYgRbcnq2"
      },
      "source": [
        "attention_masks = []\r\n",
        "\r\n",
        "for sent in input_ids:\r\n",
        "    # set mask to 0 if token_id is 0 (becoz its padding) and vice versa\r\n",
        "    attn_mask = [int(token_id > 0) for token_id in sent]\r\n",
        "    attention_masks.append(attn_mask)\r\n"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j4bGHKDcpIG",
        "outputId": "c8b64b71-82fe-428f-8d69-91c09c56beaf"
      },
      "source": [
        "t.Tensor(attention_masks)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLZtegqUnOhb",
        "outputId": "b400c0aa-8429-47e4-c493-d635a50bd580"
      },
      "source": [
        "t.Tensor(input_ids)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 5.8100e+02, 5.0339e+04, 1.6836e+05, 4.5000e+02, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 1.1100e+02, 7.0000e+01, 2.9204e+04, 7.0000e+00,\n",
              "         9.8000e+01, 2.1507e+04, 1.3300e+02, 4.3011e+04, 2.1400e+02, 4.0000e+00,\n",
              "         7.0700e+02, 2.1859e+04, 4.7898e+04, 2.5860e+03, 2.9700e+02, 2.1400e+02,\n",
              "         7.2201e+04, 2.7771e+04, 4.0000e+00, 1.3600e+02, 2.8430e+03, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 2.3000e+01, 7.0000e+01, 3.6298e+04, 4.0000e+00,\n",
              "         7.0700e+02, 1.1926e+05, 2.8900e+02, 2.3600e+03, 7.4800e+02, 4.2000e+01,\n",
              "         5.2800e+02, 9.9660e+03, 4.0000e+00, 3.5420e+03, 1.3727e+05, 6.7800e+02,\n",
              "         2.7226e+04, 1.3864e+04, 3.1300e+02, 9.0926e+04, 2.3000e+01, 7.0000e+01,\n",
              "         5.9714e+04, 8.6429e+04, 5.0000e+00, 3.4930e+03, 4.0000e+00, 7.0000e+01,\n",
              "         2.5188e+04, 1.3140e+03, 1.4037e+04, 4.5000e+02, 1.1806e+05, 3.1815e+04,\n",
              "         2.3000e+01, 7.8219e+04, 1.1100e+02, 1.3864e+04, 3.1300e+02, 2.3000e+01,\n",
              "         8.3820e+03, 3.3950e+03, 6.7800e+02, 2.7226e+04, 1.3864e+04, 3.1300e+02,\n",
              "         8.0796e+04, 9.0926e+04, 1.0490e+05, 4.7000e+01, 3.9531e+04, 1.8400e+02,\n",
              "         6.0970e+03, 2.5860e+03, 2.9700e+02, 2.1400e+02, 3.7348e+04, 5.0000e+00,\n",
              "         6.6190e+03, 3.8516e+04, 8.9515e+04, 3.2900e+02, 4.0000e+00, 1.7378e+04,\n",
              "         7.6740e+03, 5.1300e+02, 5.8300e+02, 4.0000e+00, 2.7500e+03, 8.3000e+01,\n",
              "         2.8430e+03, 1.4200e+02, 6.0600e+02, 1.7043e+04, 1.5390e+04, 1.6030e+04,\n",
              "         1.1100e+02, 8.3063e+04, 2.5443e+04, 2.3000e+01, 7.0000e+01, 3.4500e+02,\n",
              "         1.4560e+03, 1.9188e+04, 1.1100e+02, 1.6934e+04, 1.9102e+04, 4.0000e+00,\n",
              "         1.5044e+04, 1.0000e+01, 2.9204e+04, 2.5860e+03, 2.9700e+02, 2.1400e+02,\n",
              "         7.2201e+04, 2.7771e+04, 1.3600e+02, 1.1926e+05, 2.8900e+02, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 5.8090e+03, 1.8600e+02, 1.0000e+01, 2.4092e+04,\n",
              "         1.1100e+02, 4.5370e+03, 6.3134e+04, 2.3000e+01, 1.6320e+03, 2.5000e+01,\n",
              "         7.0000e+00, 1.1948e+04, 4.0790e+03, 2.5667e+04, 5.4260e+03, 4.0000e+00,\n",
              "         1.1100e+02, 1.0000e+01, 1.1948e+04, 4.0790e+03, 2.5667e+04, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 7.2201e+04, 2.7771e+04, 2.3000e+01, 7.0000e+01,\n",
              "         7.8574e+04, 4.0000e+00, 2.6498e+04, 1.3600e+02, 2.0000e+02, 1.0952e+04,\n",
              "         4.7780e+03, 5.0000e+00, 5.8100e+02, 3.5187e+04, 1.4602e+04, 9.5900e+02,\n",
              "         2.1980e+04, 5.3800e+02, 4.5000e+02, 6.5771e+04, 3.9531e+04, 6.9530e+03,\n",
              "         1.1100e+02, 1.4200e+02, 1.2474e+05, 2.1859e+04, 4.7898e+04, 2.5860e+03,\n",
              "         2.9700e+02, 2.1400e+02, 7.2201e+04, 2.7771e+04, 6.7800e+02, 1.3864e+04,\n",
              "         3.1300e+02, 1.2210e+03, 5.6282e+04, 1.2047e+05, 7.0000e+00, 7.0700e+02,\n",
              "         3.7890e+03, 8.5583e+04, 1.6227e+04, 1.8434e+05, 7.0000e+00, 4.0000e+00,\n",
              "         7.6740e+03, 5.1300e+02, 5.8300e+02, 1.1405e+04, 9.0000e+01, 5.0000e+00,\n",
              "         3.3306e+04, 4.0000e+00, 7.0000e+01, 5.0339e+04, 5.4000e+01, 4.2459e+04,\n",
              "         4.5000e+02, 1.3864e+04, 3.1300e+02, 2.0924e+05, 8.2775e+04, 1.0292e+05,\n",
              "         5.3800e+02, 4.7000e+01, 5.9959e+04, 2.6548e+04, 9.1000e+01, 1.6820e+04,\n",
              "         3.0330e+03, 2.9200e+02, 1.0000e+01, 1.0349e+05, 5.3800e+02, 7.0997e+04,\n",
              "         1.4343e+05, 3.9000e+02, 1.1153e+05, 2.7226e+04, 1.3864e+04, 3.1300e+02,\n",
              "         9.0926e+04, 2.9200e+02, 6.2100e+02, 5.7920e+03, 2.7226e+04, 4.0000e+00,\n",
              "         1.3600e+02, 4.5000e+02, 6.0440e+03, 1.0000e+01, 2.7226e+04, 1.3864e+04,\n",
              "         3.1300e+02, 2.3000e+01, 7.8219e+04, 8.3100e+02, 3.7105e+04, 4.7000e+01,\n",
              "         1.0000e+01, 2.5860e+03, 2.9700e+02, 2.1400e+02, 7.2201e+04, 2.7771e+04,\n",
              "         4.0000e+00, 3.1290e+03, 5.6080e+03, 9.5900e+02, 1.8600e+02, 1.9161e+05,\n",
              "         6.7800e+02, 1.3055e+05, 2.1917e+04, 7.0000e+00, 7.0000e+00, 5.0000e+00,\n",
              "         1.6570e+03, 1.8400e+02, 2.6513e+04, 1.8000e+01, 5.3800e+02, 4.0000e+00,\n",
              "         7.6740e+03, 5.1300e+02, 5.8300e+02, 1.4602e+04, 6.7330e+04, 3.3950e+03,\n",
              "         8.1887e+04, 4.7000e+01, 1.3695e+04, 1.4200e+02, 3.6298e+04, 9.8000e+01,\n",
              "         2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCXyFmyUcyv2"
      },
      "source": [
        "#input_ids = batch[0].to(device)    # The main training data\r\n",
        "input_ids = t.Tensor(input_ids).long().to(device)  \r\n",
        "attention_mask = t.Tensor(attention_masks).long().to(device)  # The input masks for padding"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-PteB6eeC_U",
        "outputId": "f3aee07f-9cd9-484b-c423-c16659781cb3"
      },
      "source": [
        "input_ids.shape"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjv9wNhtnf2y",
        "outputId": "8ed0d0d7-fad1-4f15-be1c-d92fe177c996"
      },
      "source": [
        "attention_mask.shape"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBZcq7NFULKN"
      },
      "source": [
        "\r\n",
        "#labels = batch[2].to(device)        # The labels \r\n",
        "\r\n",
        "with t.no_grad():\r\n",
        "  outputs = model(input_ids, attention_mask=attention_mask)\r\n",
        "\r\n",
        "logits = outputs[0]\r\n",
        "logits = logits.detach().cpu().numpy()\r\n",
        "#label_ids = labels.to('cpu').numpy()\r\n",
        "pred_flat = np.argmax(logits, axis = 1).flatten()\r\n",
        "#labels_flat = label_ids.flatten()\r\n",
        "\r\n",
        "y_pred.append(pred_flat[0])\r\n",
        "#y_true.append(labels_flat[0])\r\n",
        "# print(pred_flat,labels_flat)"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rqNdZEWdEZP"
      },
      "source": [
        "y_true = df_art.iloc[i].Mobile_Tech_Flag"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bt3ng9yoGvZ",
        "outputId": "7c1d081e-1414-420a-88ef-58184b5b2c7b"
      },
      "source": [
        "y_true"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9qvV1fadEeh",
        "outputId": "f4890f8a-d9e0-4800-e915-0cf7e636b2b5"
      },
      "source": [
        "pred_flat"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xnPpUenohjF"
      },
      "source": [
        ""
      ],
      "execution_count": 263,
      "outputs": []
    }
  ]
}