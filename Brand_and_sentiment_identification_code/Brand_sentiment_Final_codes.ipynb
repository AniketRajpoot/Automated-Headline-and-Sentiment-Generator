{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final codes.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"r954-g5xNNuh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616533833334,"user_tz":-330,"elapsed":7055,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}},"outputId":"9c0d4365-141f-40d7-e112-c0d16f693209"},"source":["!pip install fuzzywuzzy\n","!pip install vaderSentiment\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (0.18.0)\n","Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aiLausbym2DE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616533834716,"user_tz":-330,"elapsed":8428,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}},"outputId":"8de541d3-2641-4a17-a517-aef5aaf18a14"},"source":["import os\n","import re\n","import sys\n","import nltk\n","import json\n","import collections\n","import numpy as np\n","import pandas as pd\n","from nltk import ngrams\n","from fuzzywuzzy import fuzz \n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords, sentiwordnet as swn\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6O50sXU1KJXO","executionInfo":{"status":"ok","timestamp":1616533834717,"user_tz":-330,"elapsed":8421,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}},"outputId":"54fecae1-34e4-48cb-ef84-0563606338b3"},"source":["nltk.download('punkt')\n","nltk.download('stopwords')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1ArU5NHgCTI","executionInfo":{"status":"ok","timestamp":1616533834717,"user_tz":-330,"elapsed":8416,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}},"outputId":"1ed7ae3b-a5a4-4926-daab-3b92f19246ad"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nmIomNETt2sK"},"source":["## Configuration cell"]},{"cell_type":"code","metadata":{"id":"XdltsfMCt1bc","executionInfo":{"status":"ok","timestamp":1616533834717,"user_tz":-330,"elapsed":8410,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["#All input and output files are present in this folder\n","data_path = '/content/drive/MyDrive/Bridgei2i Inter-IIT NLP Competition/Submit_data/'\n","#Initializing the brand name list\n","BN1 = np.array(['sitronics','apple','cherry','nexian','polytron','vestel','micromax','wileyfox','xiaomi','genpro','starmobile','lenovo','blackberry','honor','fujitsu','karbonn','reliance',\n","        'mobiistar','celkon', 'caterpillar', 'lg', 'philips','hcl', 'google','coolpad','gionee','realme', 'motorola', 'lenovo', 'oneplus', 'videocon'])\n","BN2 = np.array(['lava', 'tecno', 'ziox', 'poco', 'tcl','spc', 'x-tigi', 'sony', 'condor', 'himax',  'asus', 'dtac', 'hp', 'gresso', 'ais',  'akai', 'e-boda',  'amoi', 'advan','purism, spc', 'zen', 'just5',  'konka', \n","        'dbtel',   'iball', 'm dot', 'cubot', 'imo', 'evolio',  'acer', 'wiko','yotaphone', 'ivoomi', 'aselsan', 'spice', 'blu', 'cloudfone', 'myphone', 'megafon', 'firefly',\n","        '10.or', 'jio', 'torque','highscreen', 'salora', 'tiptel', 'bbk', 'nec', 'haier', 'ulefone', 'ningbo bird', 'wasam', 'hicore', 'axioo','koryolink',  'dopod', \n","        'iqoo', 'medion', 'manta', 'kt tech', 'nextbit', 'vinsmart', 'venera', 'nubia', 'lanix','groupe bull', 'comio', 'osmo', 'mito', 'vivo', 'technisat','andromax', 'mitsubishi', 'zte', \n","        'sansui', 'meitu', 'ninetology', 'creo', 'explay','gigaset', 'panasonic', 'samsung', 'tecno', 'texet','smartisan', 'verzo', 'vodafone', 'positivo', 'obi worldphone',\n","        'jrc', 'bullitt', 'allview', 'garmin','intex', 'centric', 'zyrex', 'thuraya','infosonics', 'oppo', 'black shark', 'beeline', 'foxconn','archos', 'asiafone', 'kyocera', 'kyoto',\n","        'swipe', 'kruger&matz', 'pantech', 'wellcom', 'gtel','vsun', 'microsoft', 'blu', 'walton','casio', 'okwu', 'yu televentures', 'roverpc', 'sico', 'olivetti', \n","        'mphone', 'gigabyte', 'mobiwire', 'gfive', 'hisense', 'datawind', 'evercoss', 'nokia', 'meizu','maxtron', 'infinix', 'utok', 'jablotron',\n","        'brondi', 'bq', 'iball', 'alcatel', 'detel', 'voice', 'mls','htc', 'intex', 'hmd', 'blackberry', 'luna', 'mts', 'kult','zopo', 'onida', 'itel', 'huawei', 'evertektunisie',\n","        'toshiba', 'jolla', 'i-mobile', 'leeco','umi', 'hitachi', 'smartron', 'benq','infocus', 'lyf', 'gradiente','bittium', 'xolo', 'zonda', 'doro', 'vitell'])\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X0UStzEs0F5T"},"source":["# Brand Identification"]},{"cell_type":"code","metadata":{"id":"ze-qSIRV_zk6","executionInfo":{"status":"ok","timestamp":1616533834718,"user_tz":-330,"elapsed":8407,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["def divideDataFrames(file_path,col_name,MT_preds_df):\n","  #df = pd.read_excel(file_path)\n","  df = pd.read_csv(file_path)\n","  df = pd.merge(df, MT_preds_df[['Text_ID','Mobile_Tech_Flag_Predicted']], on='Text_ID') \n","  mobile_tech_text = df.loc[df[col_name]==1]\n","  non_mobile_tech_text = df.loc[df[col_name]==0]\n","  return mobile_tech_text, non_mobile_tech_text"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"uRboMFfHAAWO","executionInfo":{"status":"ok","timestamp":1616533834718,"user_tz":-330,"elapsed":8404,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["# supporting functions\n","\n","def Func_tokens_create(tweet):\n","  list_of_tokens=tweet.split(\" \")\n","  return list_of_tokens\n","\n","def ratio_length(token,mobile):\n","  if min(len(token),len(mobile))/ max(len(token),len(mobile)) >0.7:\n","    return True\n","  else:\n","    return False\n","\n","def Fetch_data(file_path):\n","  df=pd.read_csv(file_path)\n","  return df\n","\n","def Find_Brands(df,cleaned_file):\n","  text_brand_names=[]\n","  matched_words=[]\n","  text_id = []\n","  for count,each_text in enumerate(cleaned_file):\n","    current_text_brand_names = []  \n","    current_matched_words = []\n","    tokenize_text = Func_tokens_create(each_text)\n","    \n","    for each_token in np.unique(tokenize_text):\n","      if each_token.isalnum():\n","        scores_list=[fuzz.ratio(each_token, word)/100 for word in BN1]\n","        if max(scores_list)>0.75:\n","          index= scores_list.index(max(scores_list))#here only top brand i have consider # we can add more if score is tie\n","          if ratio_length(each_token,BN1[index]):\n","            brand_name=BN1[index]\n","            current_text_brand_names.append(brand_name)\n","            current_matched_words.append(each_token)\n","        if each_token in BN2:\n","          current_text_brand_names.append(each_token)\n","          current_matched_words.append(each_token)\n","    text_brand_names.append(current_text_brand_names)  \n","    matched_words.append(current_matched_words)\n","  return text_brand_names, matched_words\n","  "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DfkJbBmnC9N","executionInfo":{"status":"ok","timestamp":1616533834718,"user_tz":-330,"elapsed":8401,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["def Brand_Identification_train():\n","\n","  #Processing the input data\n","  MTAdf, NMTAdf = divideDataFrames(data_path+'dev_data_article.xlsx','Mobile_Tech_Flag')\n","  MTTdf, NMTTdf = divideDataFrames(data_path+'dev_data_tweet.xlsx','Mobile_Tech_Tag')\n","\n","  #Processing the tweets\n","  df_tweet = Fetch_data(data_path+'dev_data_tweet_translated.csv')\n","  df_tweet = df_tweet[['Tweet_ID','Tweet', 'Mobile_Tech_Tag']]\n","  df_tweet['remove_lower_punct'] = df_tweet['Tweet'].str.lower().str.replace(\"'\", '').str.replace('[^\\w\\s]', ' ').str.replace(\" \\d+\", \" \").str.replace(' +', ' ').str.strip()\n","  df_tweet['remove_lower_punct'] = df_tweet.apply(lambda row: re.sub(r\"http\\S+\", \"\", row['remove_lower_punct']), axis=1)\n","  final_cleaned_tweets = df_tweet['remove_lower_punct'].to_numpy()\n","  tweet_brand_names, tweet_matched_words = Find_Brands(df_tweet,final_cleaned_tweets)\n","\n","  #Processing the articles\n","  df_articles = Fetch_data(data_path+'Mob_tech_articles.csv')\n","  df_articles = df_articles[['Text_ID','Text', 'Mobile_Tech_Flag']]\n","  df_articles['remove_lower_punct'] = df_articles['Text'].str.lower().str.replace(\"'\", '').str.replace('[^\\w\\s]', ' ').str.replace(\" \\d+\", \" \").str.replace(' +', ' ').str.strip()\n","  df_articles['remove_lower_punct'] = df_articles.apply(lambda row: re.sub(r\"http\\S+\", \"\", row['remove_lower_punct']), axis=1)\n","  final_cleaned_articles = df_articles['remove_lower_punct'].to_numpy()\n","  article_brand_names, article_matched_words = Find_Brands(df_articles,final_cleaned_articles)\n","  \n","  \n","  Output_Dataframe = pd.DataFrame()\n","  Output_Dataframe['Text_ID'] = np.append(df_articles['Text_ID'],df_tweet['Tweet_ID'])\n","  Output_Dataframe['Mobile_Tech_Flag_Predicted'] =  \"\"\n","  Output_Dataframe['Brands_Entity_Identified'] =  np.append(article_brand_names,tweet_brand_names)\n","  Output_Dataframe['Sentiment_Identified'] =  \"\"\n","  Output_Dataframe['Text'] =  np.append(final_cleaned_articles,final_cleaned_tweets)\n","  \n","  temp = Output_Dataframe.apply(pd.Series.explode)\n","\n","  NM_Output_Dataframe =pd.DataFrame()\n","  NM_Output_Dataframe['Text_ID'] =  np.append(NMTAdf['Text_ID'],NMTTdf['Tweet_ID'])\n","  NM_Output_Dataframe['Mobile_Tech_Flag_Predicted'] =  \"\"\n","  NM_Output_Dataframe['Brands_Entity_Identified'] =  \"\"\n","  NM_Output_Dataframe['Sentiment_Identified'] =  \"\"\n","  NM_Output_Dataframe['Text'] =  np.append(NMTAdf['Text'],NMTTdf['Tweet'])\n","  \n","  result = pd.concat([temp,NM_Output_Dataframe])\n","  result.to_csv(data_path+'FINAL_OUTPUT_2.csv')\n","  print(\"Train Brands Extracted Successfully!\")\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUlmTU4oEmH0","executionInfo":{"status":"ok","timestamp":1616533834719,"user_tz":-330,"elapsed":8398,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["def Brand_Identification_test():\n","\n","  #Processing the input data\n","  MT_Flag_predicted = pd.read_csv(data_path+'valid_data_1.csv')\n","  MT_texts, NMT_texts = divideDataFrames(data_path+'evaluation_data_translated.csv','Mobile_Tech_Flag_Predicted',MT_Flag_predicted)\n","  \n","  #Processing the tweets\n","  df_text = MT_texts\n","  df_text = df_text[['Text_ID','Text', 'Mobile_Tech_Flag_Predicted']]\n","  df_text['remove_lower_punct'] = df_text['Text'].str.lower().str.replace(\"'\", '').str.replace('[^\\w\\s]', ' ').str.replace(\" \\d+\", \" \").str.replace(' +', ' ').str.strip()\n","  df_text['remove_lower_punct'] = df_text.apply(lambda row: re.sub(r\"http\\S+\", \"\", row['remove_lower_punct']), axis=1)\n","  final_cleaned_text = df_text['remove_lower_punct'].to_numpy()\n","  text_brand_names, text_matched_words = Find_Brands(df_text,final_cleaned_text)\n","  \n","  Output_Dataframe = pd.DataFrame()\n","  Output_Dataframe['Text_ID'] = MT_texts['Text_ID']\n","  Output_Dataframe['Mobile_Tech_Flag_Predicted'] = MT_texts['Mobile_Tech_Flag_Predicted']\n","  Output_Dataframe['Brands_Entity_Identified'] =  text_brand_names\n","  Output_Dataframe['Sentiment_Identified'] =  \"\"\n","  Output_Dataframe['Text'] =  final_cleaned_text\n","  \n","  temp = Output_Dataframe.apply(pd.Series.explode)\n","\n","  NM_Output_Dataframe =pd.DataFrame()\n","  NM_Output_Dataframe['Text_ID'] =  NMT_texts['Text_ID']\n","  NM_Output_Dataframe['Mobile_Tech_Flag_Predicted'] =  NMT_texts['Mobile_Tech_Flag_Predicted']\n","  NM_Output_Dataframe['Brands_Entity_Identified'] =  \"\"\n","  NM_Output_Dataframe['Sentiment_Identified'] =  \"\"\n","  NM_Output_Dataframe['Text'] =  NMT_texts['Text']\n","  \n","  result = pd.concat([temp,NM_Output_Dataframe])\n","  result.to_csv(data_path+'Evaluation_Output_2.csv')\n","  print(\"Evaluation Brands Extracted Successfully!\")\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gf_iKKVE7kAY","executionInfo":{"status":"ok","timestamp":1616533848512,"user_tz":-330,"elapsed":22184,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}},"outputId":"4d993f9d-01e5-47af-ef74-74037a9945d0"},"source":["#Brand_Identification_train()\n","Brand_Identification_test()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Evaluation Brands Extracted Successfully!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j1K6lBP1NUR_"},"source":["# Single Sentiment Analysis"]},{"cell_type":"code","metadata":{"id":"wG6x47hhNc8p","executionInfo":{"status":"ok","timestamp":1616533848513,"user_tz":-330,"elapsed":22180,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["def find_sentiment(sentence_list):\n","    analyser = SentimentIntensityAnalyzer()\n","\n","    sentiment_score_list = []\n","    sentiment_label_list = []\n","\n","    for sentence in sentence_list:\n","        sentiment_score = analyser.polarity_scores(sentence)\n","\n","        if sentiment_score['compound'] >= 0.05:\n","            sentiment_score_list.append(sentiment_score['compound'])\n","            sentiment_label_list.append('Positive')\n","        elif sentiment_score['compound'] > -0.05 and sentiment_score['compound'] < 0.05:\n","            sentiment_score_list.append(sentiment_score['compound'])\n","            sentiment_label_list.append('Neutral')\n","        elif sentiment_score['compound'] <= -0.05:\n","            sentiment_score_list.append(sentiment_score['compound'])\n","            sentiment_label_list.append('Negative')\n","        \n","    return sentiment_label_list, sentiment_score_list"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sA6QHG-JNZIx"},"source":["# Multi Brand Sentiment Analysis"]},{"cell_type":"code","metadata":{"id":"huqZ2_9GNnu3","executionInfo":{"status":"ok","timestamp":1616533848513,"user_tz":-330,"elapsed":22176,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["def most_frequent(List): \n","    occurence_count = Counter(List) \n","    return occurence_count.most_common(1)[0][0]\n","\n","def partition_one(brand_list, sentence):\n","    middle_part_list = []\n","    brand=brand_list[0]\n","    all_part = sentence.split(brand)\n","    p1=all_part[0].split()\n","    p2=all_part[1].split()\n","    middle_part = ' '.join(p1[len(p1)//2:])+' '+brand+' '\n","    middle_part += ' '.join(p2[:len(p2)//2])\n","    middle_part_list.append(middle_part)\n","    return middle_part_list\n","\n","def partition_three(brand_list, sentence):\n","    prefix_part_list = []\n","    middle_part_list = []\n","    suffix_part_list = []\n","    brand=brand_list[0]\n","    all_part = sentence.split(brand)\n","    prefix_part = ''.join(all_part[0])+' '+brand\n","    suffix_part = brand+' '+''.join(all_part[1:])\n","    splitted = prefix_part.split(' ')\n","    p1=all_part[0].split()\n","    p2=all_part[1].split()\n","    middle_part = ' '.join(p1[len(p1)//2:])+' '+brand+' '\n","    middle_part += ' '.join(p2[:len(p2)//2])\n","    prefix_part_list.append(prefix_part)\n","    middle_part_list.append(middle_part)\n","    suffix_part_list.append(suffix_part)\n","    return prefix_part_list, middle_part_list, suffix_part_list"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"l3zeRfFZoew3","executionInfo":{"status":"ok","timestamp":1616533848513,"user_tz":-330,"elapsed":22171,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["def sub_main(brand_names_list,tweet_or_text):\n","  sentiment_list=[]\n","  if len(tweet_or_text) <= 280:\n","    m = partition_one(brand_names_list,tweet_or_text)\n","    #print(m)\n","    result=find_sentiment(m)\n","    sentiment_list.append(result[0][0])\n","\n","  else:\n","    p, m, s = partition_three(brand_names_list, tweet_or_text)\n","    sentiments = [find_sentiment(p),\n","                  find_sentiment(m),\n","                  find_sentiment(s)]\n","    sentiments_list= []\n","    for i in range(len(sentiments)):\n","      sentiments_list.append(sentiments[i][0])\n"," \n","    sentiments_np=np.array(sentiments_list)\n","    for i in range(0,sentiments_np.shape[1]):\n","      sentiment_list.append(most_frequent(sentiments_np[:,i]))\n","  return sentiment_list"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXwyON4N37Lf","executionInfo":{"status":"ok","timestamp":1616533848514,"user_tz":-330,"elapsed":22168,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}}},"source":["def main(eval_data_path):\n","  Brand_Identification_test()\n","  print(\"Brand Identification Process is done!!!\")\n","  df=pd.read_csv(eval_data_path,index_col=0)\n","  print(\"Total Records\",len(df))\n","  for row in range(0,len(df)):\n","    brand_names_list=df['Brands_Entity_Identified'].iloc[row]\n","    text=df['Text'].iloc[row]\n","    if row%100==0:\n","      print('Sentiments for',row,'records have been computed so far!!!')\n","    if brand_names_list is  np.nan:\n","      continue\n","    result=sub_main(brand_names_list,text)\n","    df['Sentiment_Identified'].iloc[row]=result[0]\n","  new_df=df[['Text_ID','Mobile_Tech_Flag_Predicted','Brands_Entity_Identified','Sentiment_Identified']]\n","  new_df.to_csv('/content/drive/MyDrive/Bridgei2i Inter-IIT NLP Competition/Submit_data/Evaluation_Output_2.csv',index=False)\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"3S1a8RUVKruD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616533874918,"user_tz":-330,"elapsed":48569,"user":{"displayName":"Rimmon Saloman Bhosale","photoUrl":"","userId":"01307082203144505161"}},"outputId":"cbc2d33f-e6a7-4eb8-fac6-478fd45a8e4a"},"source":["eval_data_path=data_path+'Evaluation_Output_2.csv'\n","main(eval_data_path)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Evaluation Brands Extracted Successfully!\n","Brand Identification Process is done!!!\n","Total Records 530\n","Sentiments for 0 records have been computed so far!!!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  iloc._setitem_with_indexer(indexer, value)\n"],"name":"stderr"},{"output_type":"stream","text":["Sentiments for 100 records have been computed so far!!!\n","Sentiments for 200 records have been computed so far!!!\n","Sentiments for 300 records have been computed so far!!!\n","Sentiments for 400 records have been computed so far!!!\n","Sentiments for 500 records have been computed so far!!!\n"],"name":"stdout"}]}]}